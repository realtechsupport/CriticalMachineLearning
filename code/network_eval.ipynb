{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.11"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLWoA4D_n447",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8b73fcd6-ac5d-43a3-b088-74de600e4cea"
      },
      "source": [
        "import os, sys, time, random, itertools\n",
        "from datetime import datetime\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "mygdrive = '/content/drive/MyDrive/ART/design+computationalthinking/code/'\n",
        "sys.path.append(mygdrive)\n",
        "from pyt_utilities import *\n",
        "\n",
        "from IPython.core.display import display, HTML\n",
        "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>.container { width:100% !important; }</style>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cx36aWAEn45I"
      },
      "source": [
        "# variables\n",
        "#root = '/home/marcbohlen/'\n",
        "root = '/content/drive/MyDrive/ART/design+computationalthinking/'\n",
        "path = root + 'data/'\n",
        "dataset = 'bali10'\n",
        "#----------------------------------------\n",
        "#pick a convolutional neural network model\n",
        "#vanillanet, alexnet, squeezenet, resnet18, resnet152, resnext50\n",
        "network = 'resnet152'\n",
        "#----------------------------------------\n",
        "pretrained = False;\n",
        "balinorms = True;           #normalization based on the bali-26 collection. See create_norms.py\n",
        "\n",
        "num_epochs = 20;\n",
        "offset = 0; img_limit = 1000; randomprune = True;\n",
        "training_percentage = 0.8;\n",
        "tpp = int(100 * training_percentage)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh0CNI49n45N"
      },
      "source": [
        "datapath = path + dataset + '/'\n",
        "resultspath = root + 'results/'\n",
        "if not os.path.exists(resultspath):\n",
        "    os.makedirs(resultspath)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpFSIUUbn45T"
      },
      "source": [
        "if(pretrained == True):\n",
        "    if(balinorms == True):\n",
        "        checkpointname = path + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms'+ '_checkpoint.pth'\n",
        "        output = resultspath + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms'+ '.jpg'\n",
        "        comment_t = dataset + ', ' + network + ', pretrainedyes_t' + str(tpp) + ', e' + str(num_epochs) + ', lim' + str(img_limit) + '_balinorms'\n",
        "        filename = resultspath + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms'+ '.csv'\n",
        "    else:\n",
        "        checkpointname = path + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_checkpoint.pth'\n",
        "        output = resultspath + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '.jpg'\n",
        "        comment_t = dataset + ', ' + network + ', pretrainedyes_t' + str(tpp) + ', e' + str(num_epochs) + ', lim' + str(img_limit)\n",
        "        filename = resultspath + dataset + '_' + network + '_pretrainedyes_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '.csv'\n",
        "else:\n",
        "    if(balinorms == True):\n",
        "        checkpointname = path + dataset + '_' + network + '_pretrainedNO_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms'+ '_checkpoint.pth'\n",
        "        output = resultspath + dataset + '_' + network + '_pretrainedyNO_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms'+ '.jpg'\n",
        "        comment_t = dataset + ', ' + network + ', pretrainedNO_t' + str(tpp) + ', e' + str(num_epochs) + ', lim' + str(img_limit) + '_balinorms'\n",
        "        filename = resultspath + dataset + '_' + network + '_pretrainedNO_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '_balinorms' + '.csv'\n",
        "    else:\n",
        "        checkpointname = path + dataset + '_' + network + '_pretrainedNO_t' + str(tpp) + '_e' + str(num_epochs) +'_lim' + str(img_limit) +  '_checkpoint.pth'\n",
        "        output = resultspath + dataset + '_' + network + '_pretrainedNO_t' + str(tpp) + '_e' + str(num_epochs) +'_lim' + str(img_limit) +  '.jpg'\n",
        "        comment_t = dataset + ', ' + network + ', pretrainedNO_t' + str(tpp) + ', e' + str(num_epochs) + ', lim' + str(img_limit)\n",
        "        filename = resultspath + dataset + '_' + network + '_pretrainedNO_t' + str(tpp) + '_e' + str(num_epochs) + '_lim' + str(img_limit) + '.csv'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mSLKZwwvn45X"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(os.path.join(datapath, x), data_transforms[x]) for x in ['train', 'val']}\n",
        "class_names = image_datasets['train'].classes\n",
        "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\" )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLR1SgHXpASJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f12e0a28-b8d9-4683-e7fe-0b7abbdbc010"
      },
      "source": [
        "print('checkpoint at: ', checkpointname)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "checkpoint at:  /content/drive/MyDrive/ART/design+computationalthinking/data/bali10_resnet152_pretrainedNO_t80_e20_lim1000_balinorms_checkpoint.pth\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5ym_0YJn45Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e75d3abc-f568-40e9-a908-8becd663cb9d"
      },
      "source": [
        "\n",
        "try:\n",
        "    model = load_checkpoint(checkpointname)\n",
        "except:\n",
        "    print('That model does not exist... ')\n",
        "    exit()\n",
        "\n",
        "print('\\n> Predicting class of input images <')\n",
        "\n",
        "for i in range (0, len(class_names)):\n",
        "    plantdatapath = datapath + 'val/' + class_names[i] + '/'\n",
        "    path, dirs, files = next(os.walk(plantdatapath))\n",
        "    limit = len(files)\n",
        "    top1 = 0; topN = 0; tk = 3\n",
        "\n",
        "    for j in range (0, limit):\n",
        "        image_path = next(itertools.islice(os.scandir(plantdatapath), j, None)).path\n",
        "        predictions, percentage, outcategory = predict_image(image_path, model, predict_transform, class_names, tk)\n",
        "        topN_ind = predictions[1].tolist()[0]\n",
        "        top1_ind = topN_ind[0]\n",
        "\n",
        "        input = image_path.split('/')[-2], image_path.split('/')[-1]\n",
        "\n",
        "        #you can check input[1] to find problematic images / categories of confusion\n",
        "        #print('\\ninput: ', input); print('output: ', outcategory, percentage)\n",
        "\n",
        "        if(class_names[top1_ind] == input[0]):\n",
        "            top1 = top1 + 1\n",
        "\n",
        "        if(check_topN(class_names, topN_ind, tk, input[0]) == 1):\n",
        "            topN = topN + 1\n",
        "\n",
        "    top1_score = float(top1 / limit)\n",
        "    topN_score = float(topN / limit)\n",
        "    top1_error = 100*float(\"%.3f\" %(1.0 - top1_score))\n",
        "    topN_error = 100*float(\"%.3f\" %(1.0 - topN_score))\n",
        "\n",
        "    comment = comment_t + ', ' + str(class_names[i])  + ', top1-error, ' + str(top1_error) + ', top' + str(tk) + '-error, ' + str(topN_error)\n",
        "    print(comment + '\\n')\n",
        "    write2file(filename, comment)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "got this far into loading checkpoint...\n",
            "now got this far into loading checkpoint...\n",
            "\n",
            "> Predicting class of input images <\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, aroid, top1-error, 56.00000000000001, top3-error, 32.5\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, dragonfruit, top1-error, 47.0, top3-error, 19.5\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, frangipani, top1-error, 73.5, top3-error, 46.0\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, jackfruit, top1-error, 34.0, top3-error, 17.0\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, nilam, top1-error, 18.0, top3-error, 1.5\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, papaya, top1-error, 76.5, top3-error, 22.0\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, passiflora, top1-error, 57.99999999999999, top3-error, 27.500000000000004\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, sawo, top1-error, 65.0, top3-error, 42.5\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, snakefruit, top1-error, 24.0, top3-error, 4.5\n",
            "\n",
            "bali10, resnet152, pretrainedNO_t80, e20, lim1000_balinorms, zodia, top1-error, 71.0, top3-error, 26.0\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D86RJ_Ccn45c"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}