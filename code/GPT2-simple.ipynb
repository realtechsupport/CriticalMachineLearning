{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"GPT2-simple.ipynb","provenance":[{"file_id":"1DUaP3Mc4-op0Fj04Qoe6s1eeJrPBx8TV","timestamp":1649856180514},{"file_id":"https://github.com/ilopezfr/gpt-2/blob/master/gpt-2-playground_.ipynb","timestamp":1643386903851}],"private_outputs":true,"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["# Experiments with gpt-2-simple on Colab\n","# source\n","# https://github.com/minimaxir/gpt-2-simple\n","# use GPU to train the model\n","# April 2022"],"metadata":{"id":"dH9-36whLcLC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# A simple Python package that wraps existing model fine-tuning and generation scripts for OpenAI's GPT-2 text generation model \n","# (specifically the \"small\" 124M and \"medium\" 355M hyperparameter versions). Additionally, this package allows easier generation of text, \n","# generating to a file for easy curation, allowing for prefixes to force the text to start with a given phrase.\n","\n","# You can use this notebook to fine tune one of the gpt2 engines with a different source #"],"metadata":{"id":"ODm0Czrymu6s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# also check\n","# https://colab.research.google.com/drive/1VLG8e7YSEwypxU-noRNhsv5dW4NfTGce\n","# for differences between gpt-simple and other text generation utilities\n","\n","# if you want to retrain this engine again, first \"disconnect and delete runtime\" from the Runtime menu"],"metadata":{"id":"HSotsCtF_rTh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# preparation\n","!pip3 install gpt-2-simple"],"metadata":{"id":"TWBFJlVTsx9r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import gpt_2_simple as gpt2\n","import os\n","import requests"],"metadata":{"id":"a1iUOzgSs739"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model_name = \"124M\"\n","\n","if not os.path.isdir(os.path.join(\"models\", model_name)):\n","\tprint(f\"Downloading {model_name} model...\")\n","\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n","\n","\n","#This works for .txt files online. If you want to ingest more complex formats (.pdf, .html) you have to do more work...\n","\n","file_name = \"chosen_text.txt\"    # a name to save the online text to.\n","if not os.path.isfile(file_name):\n","  #select an input source that is online (to make things easy).Below two examples: Shakespear and the Unabomber\n","\t#url_shakespeare = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n","  url_unabomber = \"https://www.josharcher.uk/static/files/2018/01/Industrial_Society_and_Its_Future-Ted_Kaczynski.txt\"\n","  data = requests.get(url_unabomber)\n","\n","  #save the input to a text tile\n","  with open(file_name, 'w') as f:\n","    f.write(data.text)\n","\n","#train the gpt2 on the selected text\n","#as the model is created, some sample text is produced every hundred iterations\n","#steps is max number of training steps - 1000 steps takes about 1 1/2 hours - 500 should be ok as well...\n","# using 200 here for the demo\n","\n","sess = gpt2.start_tf_sess()\n","gpt2.finetune(sess,\n","              file_name,\n","              model_name=model_name,\n","              steps=200)   "],"metadata":{"id":"ilof9isMtAYg"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#generate some new text of length 25 with a specific prefix\n","gpt2.generate(sess,\n","              length=25,\n","              temperature=0.7,\n","              prefix=\"Science\",\n","              nsamples=5,\n","              batch_size=5\n","              )"],"metadata":{"id":"LsX7fdoNA8XE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["gpt2.generate(sess,\n","              length=25,\n","              temperature=0.7,\n","              prefix=\"Violence\",\n","              nsamples=5,\n","              batch_size=5\n","              )"],"metadata":{"id":"pU2QNA9nBS3K"},"execution_count":null,"outputs":[]}]}