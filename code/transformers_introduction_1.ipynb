{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOCv4KQrldMUismTtP2cjkF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"m6BU1KWlu9Vh"},"outputs":[],"source":["# Large Language Models - Transformers - 1\n","\n","# original paper:  Vawani et al. Attention is all you need. 2017.\n","# https://arxiv.org/pdf/1706.03762.pdf\n","\n","# overview of the concept: https://quantdare.com/transformers-is-attention-all-we-need-in-finance-part-i/\n","\n","# base model in pytorch\n","# https://towardsdatascience.com/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n","# https://nlp.seas.harvard.edu/2018/04/03/attention.html\n","\n","# Nvidia version of the transformer model\n","# https://blogs.nvidia.com/blog/2022/03/25/what-is-a-transformer-model/\n","\n","# (first two images from:  https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n","# third image from Vawani paper\n","\n","# Code scratched from:\n","# Daniel Melchor: https://medium.com/@danielmelchor/a-detailed-guide-to-pytorchs-nn-transformer-module-c80afbc9ffb1\n","\n"]},{"cell_type":"markdown","source":["<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/RNN-unrolled.png\" width=\"600\">\n","\n","<br><br>\n","\n","<img src=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-chain.png\" width=\"600\">\n","\n","<br><br>\n","\n","<img src=\"https://quantdare.com/wp-content/uploads/2021/11/transformer_arch.png\" width=\"600\">"],"metadata":{"id":"BbeugTiQ3mA0"}},{"cell_type":"code","source":["\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","\n","import math\n","import numpy as np"],"metadata":{"id":"j3phdXJ_v6si","executionInfo":{"status":"ok","timestamp":1683061214560,"user_tz":240,"elapsed":8804,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","\n","    # Constructor\n","    def __init__(\n","        self,\n","        num_tokens,\n","        dim_model,\n","        num_heads,\n","        num_encoder_layers,\n","        num_decoder_layers,\n","        dropout_p,\n","    ):\n","        super().__init__()\n","\n","        # INFO\n","        self.model_type = \"Transformer\"\n","        self.dim_model = dim_model\n","\n","        # LAYERS\n","        self.positional_encoder = PositionalEncoding(\n","            dim_model=dim_model, dropout_p=dropout_p, max_len=5000\n","        )\n","        self.embedding = nn.Embedding(num_tokens, dim_model)\n","        self.transformer = nn.Transformer(\n","            d_model=dim_model,\n","            nhead=num_heads,\n","            num_encoder_layers=num_encoder_layers,\n","            num_decoder_layers=num_decoder_layers,\n","            dropout=dropout_p,\n","        )\n","        self.out = nn.Linear(dim_model, num_tokens)\n","        \n","    def forward(self, src, tgt, tgt_mask=None, src_pad_mask=None, tgt_pad_mask=None):\n","        # Src size must be (batch_size, src sequence length)\n","        # Tgt size must be (batch_size, tgt sequence length)\n","\n","        # Embedding + positional encoding - Out size = (batch_size, sequence length, dim_model)\n","        src = self.embedding(src) * math.sqrt(self.dim_model)\n","        tgt = self.embedding(tgt) * math.sqrt(self.dim_model)\n","        src = self.positional_encoder(src)\n","        tgt = self.positional_encoder(tgt)\n","        \n","        # We could use the parameter batch_first=True, but our KDL version doesn't support it yet, so we permute\n","        # to obtain size (sequence length, batch_size, dim_model),\n","        src = src.permute(1,0,2)\n","        tgt = tgt.permute(1,0,2)\n","\n","        # Transformer blocks - Out size = (sequence length, batch_size, num_tokens)\n","        transformer_out = self.transformer(src, tgt, tgt_mask=tgt_mask, src_key_padding_mask=src_pad_mask, tgt_key_padding_mask=tgt_pad_mask)\n","        out = self.out(transformer_out)\n","        \n","        return (out)\n","      \n","    def get_tgt_mask(self, size) -> torch.tensor:\n","        # Generates a square matrix where the each row allows one word more to be seen\n","        mask = torch.tril(torch.ones(size, size) == 1) # Lower triangular matrix\n","        mask = mask.float()\n","        mask = mask.masked_fill(mask == 0, float('-inf')) # Convert zeros to -inf\n","        mask = mask.masked_fill(mask == 1, float(0.0)) # Convert ones to 0\n","        \n","        # EX for size=5:\n","        # [[0., -inf, -inf, -inf, -inf],\n","        #  [0.,   0., -inf, -inf, -inf],\n","        #  [0.,   0.,   0., -inf, -inf],\n","        #  [0.,   0.,   0.,   0., -inf],\n","        #  [0.,   0.,   0.,   0.,   0.]]\n","        \n","        return (mask)\n","    \n","    def create_pad_mask(self, matrix: torch.tensor, pad_token: int) -> torch.tensor:\n","        # If matrix = [1,2,3,0,0,0] where pad_token=0, the result mask is\n","        # [False, False, False, True, True, True]\n","        return ((matrix == pad_token))"],"metadata":{"id":"0maRiy-7v7iH","executionInfo":{"status":"ok","timestamp":1683061220242,"user_tz":240,"elapsed":151,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, dim_model, dropout_p, max_len):\n","        super().__init__()\n","        # Modified version from: https://pytorch.org/tutorials/beginner/transformer_tutorial.html\n","        # max_len determines how far the position can have an effect on a token (window)\n","        \n","        # Info\n","        self.dropout = nn.Dropout(dropout_p)\n","        \n","        # Encoding - From formula\n","        pos_encoding = torch.zeros(max_len, dim_model)\n","        positions_list = torch.arange(0, max_len, dtype=torch.float).view(-1, 1) # 0, 1, 2, 3, 4, 5\n","        division_term = torch.exp(torch.arange(0, dim_model, 2).float() * (-math.log(10000.0)) / dim_model) # 1000^(2i/dim_model)\n","        \n","        # PE(pos, 2i) = sin(pos/1000^(2i/dim_model))\n","        pos_encoding[:, 0::2] = torch.sin(positions_list * division_term)\n","        \n","        # PE(pos, 2i + 1) = cos(pos/1000^(2i/dim_model))\n","        pos_encoding[:, 1::2] = torch.cos(positions_list * division_term)\n","        \n","        # Saving buffer (same as parameter without gradients needed)\n","        pos_encoding = pos_encoding.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer(\"pos_encoding\",pos_encoding)\n","        \n","    def forward(self, token_embedding: torch.tensor) -> torch.tensor:\n","        # Residual connection + pos encoding\n","        return (self.dropout(token_embedding + self.pos_encoding[:token_embedding.size(0), :]))"],"metadata":{"id":"5nobmCSPwHcZ","executionInfo":{"status":"ok","timestamp":1683061227238,"user_tz":240,"elapsed":140,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["import random\n","\n","def generate_random_data(n):\n","    SOS_token = np.array([2])\n","    EOS_token = np.array([3])\n","    length = 8\n","\n","    data = []\n","\n","    # 1,1,1,1,1,1 -> 1,1,1,1,1\n","    for i in range(n // 3):\n","        X = np.concatenate((SOS_token, np.ones(length), EOS_token))\n","        y = np.concatenate((SOS_token, np.ones(length), EOS_token))\n","        data.append([X, y])\n","\n","    # 0,0,0,0 -> 0,0,0,0\n","    for i in range(n // 3):\n","        X = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n","        y = np.concatenate((SOS_token, np.zeros(length), EOS_token))\n","        data.append([X, y])\n","\n","    # 1,0,1,0 -> 1,0,1,0,1\n","    for i in range(n // 3):\n","        X = np.zeros(length)\n","        start = random.randint(0, 1)\n","\n","        X[start::2] = 1\n","\n","        y = np.zeros(length)\n","        if X[-1] == 0:\n","            y[::2] = 1\n","        else:\n","            y[1::2] = 1\n","\n","        X = np.concatenate((SOS_token, X, EOS_token))\n","        y = np.concatenate((SOS_token, y, EOS_token))\n","\n","        data.append([X, y])\n","\n","    np.random.shuffle(data)\n","\n","    return (data)\n","\n","\n","def batchify_data(data, batch_size=16, padding=False, padding_token=-1):\n","    batches = []\n","    for idx in range(0, len(data), batch_size):\n","        # We make sure we dont get the last bit if its not batch_size size\n","        if idx + batch_size < len(data):\n","            # Here you would need to get the max length of the batch,\n","            # and normalize the length with the PAD token.\n","            if padding:\n","                max_batch_length = 0\n","\n","                # Get longest sentence in batch\n","                for seq in data[idx : idx + batch_size]:\n","                    if len(seq) > max_batch_length:\n","                        max_batch_length = len(seq)\n","\n","                # Append X padding tokens until it reaches the max length\n","                for seq_idx in range(batch_size):\n","                    remaining_length = max_bath_length - len(data[idx + seq_idx])\n","                    data[idx + seq_idx] += [padding_token] * remaining_length\n","\n","            batches.append(np.array(data[idx : idx + batch_size]).astype(np.int64))\n","\n","    print(f\"{len(batches)} batches of size {batch_size}\")\n","\n","    return (batches)\n","\n","\n","train_data = generate_random_data(9000)\n","val_data = generate_random_data(3000)\n","\n","train_dataloader = batchify_data(train_data)\n","val_dataloader = batchify_data(val_data)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"V4q80p6uw8aV","executionInfo":{"status":"ok","timestamp":1683061336245,"user_tz":240,"elapsed":328,"user":{"displayName":"m b","userId":"01661067310575909085"}},"outputId":"2696f2f3-6a71-4f1e-dcba-f625499d9cc0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["562 batches of size 16\n","187 batches of size 16\n"]}]},{"cell_type":"code","source":["device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model = Transformer(num_tokens=4, dim_model=8, num_heads=2, num_encoder_layers=3, num_decoder_layers=3, dropout_p=0.1).to(device)\n","opt = torch.optim.SGD(model.parameters(), lr=0.01)\n","loss_fn = nn.CrossEntropyLoss()"],"metadata":{"id":"9PPXsT2lxRRs","executionInfo":{"status":"ok","timestamp":1683061346365,"user_tz":240,"elapsed":720,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def train_loop(model, opt, loss_fn, dataloader):\n","  \n","    model.train()\n","    total_loss = 0\n","    \n","    for batch in dataloader:\n","        X, y = batch[:, 0], batch[:, 1]\n","        X, y = torch.tensor(X).to(device), torch.tensor(y).to(device)\n","\n","        # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n","        y_input = y[:,:-1]\n","        y_expected = y[:,1:]\n","        \n","        # Get mask to mask out the next words\n","        sequence_length = y_input.size(1)\n","        tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n","\n","        # Standard training except we pass in y_input and tgt_mask\n","        pred = model(X, y_input, tgt_mask)\n","\n","        # Permute pred to have batch size first again\n","        pred = pred.permute(1, 2, 0)      \n","        loss = loss_fn(pred, y_expected)\n","\n","        opt.zero_grad()\n","        loss.backward()\n","        opt.step()\n","    \n","        total_loss += loss.detach().item()\n","        \n","    return (total_loss / len(dataloader))\n"],"metadata":{"id":"Qp4HrLooxYlG","executionInfo":{"status":"ok","timestamp":1683061366084,"user_tz":240,"elapsed":217,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["def validation_loop(model, loss_fn, dataloader):\n","\n","    model.eval()\n","    total_loss = 0\n","    \n","    with torch.no_grad():\n","        for batch in dataloader:\n","            X, y = batch[:, 0], batch[:, 1]\n","            X, y = torch.tensor(X, dtype=torch.long, device=device), torch.tensor(y, dtype=torch.long, device=device)\n","\n","            # Now we shift the tgt by one so with the <SOS> we predict the token at pos 1\n","            y_input = y[:,:-1]\n","            y_expected = y[:,1:]\n","            \n","            # Get mask to mask out the next words\n","            sequence_length = y_input.size(1)\n","            tgt_mask = model.get_tgt_mask(sequence_length).to(device)\n","\n","            # Standard training except we pass in y_input and src_mask\n","            pred = model(X, y_input, tgt_mask)\n","\n","            # Permute pred to have batch size first again\n","            pred = pred.permute(1, 2, 0)      \n","            loss = loss_fn(pred, y_expected)\n","            total_loss += loss.detach().item()\n","        \n","    return (total_loss / len(dataloader))"],"metadata":{"id":"8s0tvDKqxavo","executionInfo":{"status":"ok","timestamp":1683061369418,"user_tz":240,"elapsed":125,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["def fit(model, opt, loss_fn, train_dataloader, val_dataloader, epochs):\n","\n","    \n","    # Used for plotting later on\n","    train_loss_list, validation_loss_list = [], []\n","    \n","    print(\"Training and validating model\")\n","    for epoch in range(epochs):\n","        print(\"-\"*25, f\"Epoch {epoch + 1}\",\"-\"*25)\n","        \n","        train_loss = train_loop(model, opt, loss_fn, train_dataloader)\n","        train_loss_list += [train_loss]\n","        \n","        validation_loss = validation_loop(model, loss_fn, val_dataloader)\n","        validation_loss_list += [validation_loss]\n","        \n","        print(f\"Training loss: {train_loss:.4f}\")\n","        print(f\"Validation loss: {validation_loss:.4f}\")\n","        print()\n","        \n","    return (train_loss_list, validation_loss_list)"],"metadata":{"id":"8T6duG1Uxghg","executionInfo":{"status":"ok","timestamp":1683061374577,"user_tz":240,"elapsed":218,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def predict(model, input_sequence, max_length=25, SOS_token=2, EOS_token=3):\n","\n","    model.eval()\n","    \n","    y_input = torch.tensor([[SOS_token]], dtype=torch.long, device=device)\n","\n","    num_tokens = len(input_sequence[0])\n","\n","    for _ in range(max_length):\n","        # Get source mask\n","        tgt_mask = model.get_tgt_mask(y_input.size(1)).to(device)\n","        \n","        pred = model(input_sequence, y_input, tgt_mask)\n","        \n","        next_item = pred.topk(1)[1].view(-1)[-1].item() # num with highest probability\n","        next_item = torch.tensor([[next_item]], device=device)\n","\n","        # Concatenate previous input with predicted best word\n","        y_input = torch.cat((y_input, next_item), dim=1)\n","\n","        # Stop if model predicts end of sentence\n","        if next_item.view(-1).item() == EOS_token:\n","            break\n","\n","    return (y_input.view(-1).tolist())"],"metadata":{"id":"cDZDkh3jyKJ-","executionInfo":{"status":"ok","timestamp":1683061377243,"user_tz":240,"elapsed":155,"user":{"displayName":"m b","userId":"01661067310575909085"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["train_loss_list, validation_loss_list = fit(model, opt, loss_fn, train_dataloader, val_dataloader, 10)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LDLDgydIxlDq","executionInfo":{"status":"ok","timestamp":1683061604660,"user_tz":240,"elapsed":219221,"user":{"displayName":"m b","userId":"01661067310575909085"}},"outputId":"6ab6586f-9ed2-4fa5-9ecb-ef458c30a7ec"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["Training and validating model\n","------------------------- Epoch 1 -------------------------\n","Training loss: 0.5018\n","Validation loss: 0.3847\n","\n","------------------------- Epoch 2 -------------------------\n","Training loss: 0.3840\n","Validation loss: 0.3229\n","\n","------------------------- Epoch 3 -------------------------\n","Training loss: 0.3380\n","Validation loss: 0.2639\n","\n","------------------------- Epoch 4 -------------------------\n","Training loss: 0.3052\n","Validation loss: 0.2291\n","\n","------------------------- Epoch 5 -------------------------\n","Training loss: 0.2813\n","Validation loss: 0.2006\n","\n","------------------------- Epoch 6 -------------------------\n","Training loss: 0.2614\n","Validation loss: 0.1848\n","\n","------------------------- Epoch 7 -------------------------\n","Training loss: 0.2494\n","Validation loss: 0.1695\n","\n","------------------------- Epoch 8 -------------------------\n","Training loss: 0.2365\n","Validation loss: 0.1616\n","\n","------------------------- Epoch 9 -------------------------\n","Training loss: 0.2321\n","Validation loss: 0.1560\n","\n","------------------------- Epoch 10 -------------------------\n","Training loss: 0.2255\n","Validation loss: 0.1510\n","\n"]}]},{"cell_type":"code","source":["# Test some examples to observe how the model predicts\n","\n","examples = []\n","examples_tensor = []\n","\n","examples =    [\n","    [2, 0, 1, 3],\n","    [2, 0, 0, 0, 0, 0, 0, 0, 0, 3],\n","    [2, 1, 1, 1, 1, 1, 1, 1, 1, 3],\n","    [2, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n","    [2, 0, 1, 0, 1, 0, 1, 0, 1, 3],\n","    [2, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 3],\n","    [2, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 3]\n","    ]\n","\n","for e in examples:\n","  t = torch.tensor([e], dtype=torch.long, device=device)\n","  examples_tensor.append(t)\n","\n","\n","for idx, example in enumerate(examples_tensor):\n","    result = predict(model, example)\n","    print(f\"Example {idx}\")\n","    print(f\"Input: {example.view(-1).tolist()[1:-1]}\")\n","    print(f\"Continuation: {result[1:-1]}\")\n","    print()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"1Oe1OEWmyStb","executionInfo":{"status":"ok","timestamp":1683061671575,"user_tz":240,"elapsed":540,"user":{"displayName":"m b","userId":"01661067310575909085"}},"outputId":"dddbd7d7-6600-499e-bccb-7f711a89dc22"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["Example 0\n","Input: [0, 1]\n","Continuation: [0, 1, 0, 1, 0, 1, 0, 1]\n","\n","Example 1\n","Input: [0, 0, 0, 0, 0, 0, 0, 0]\n","Continuation: [0, 0, 0, 0, 0, 0, 0, 0]\n","\n","Example 2\n","Input: [1, 1, 1, 1, 1, 1, 1, 1]\n","Continuation: [1, 1, 1, 1, 1, 1, 1, 1, 1]\n","\n","Example 3\n","Input: [1, 0, 1, 0, 1, 0, 1, 0]\n","Continuation: [1, 0, 1, 0, 1, 0, 1, 0]\n","\n","Example 4\n","Input: [0, 1, 0, 1, 0, 1, 0, 1]\n","Continuation: [1, 0, 1, 0, 1, 0, 1, 0]\n","\n","Example 5\n","Input: [0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0]\n","Continuation: [0, 1, 0, 1, 0, 1, 0, 1]\n","\n","Example 6\n","Input: [1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1]\n","Continuation: [1, 1, 0, 1, 0, 1, 0, 1]\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"PbH4Tr1uzgiL"},"execution_count":null,"outputs":[]}]}